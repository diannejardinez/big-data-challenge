# ETL on Big Data - PySpark & AWS's Relational Databases

**Level 1 Objective**:

Perform ETL process completely in the cloud and upload a DataFrame to an RDS instance by creating 4 DataFrames to match production-ready tables from two big Amazon customer review datasets

### ETL: Outdoors Dataset
- Extracted: 2,302,173 number of records
- Transformed
![](https://github.com/diannejardinez/big-data-challenge/blob/master/Images/Outdoors-Table-Query/Outdoors-Schema-all_tables.png)
- Load
![](https://github.com/diannejardinez/big-data-challenge/blob/master/Images/Outdoors-Table-Query/Outdoors-RDS-all_tables.png)



### ETL: Digital Video Games Dataset
- Extracted: 145,431 number of records
- Transformed
![](https://github.com/diannejardinez/big-data-challenge/blob/master/Images/Digital_Video_Games-Table-Query/Video_games-Schema-all_tables.png)
- Load
![](https://github.com/diannejardinez/big-data-challenge/blob/master/Images/Digital_Video_Games-Table-Query/Video_games-RDS-all_tables.png)